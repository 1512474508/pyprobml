# Jupyter Notebooks for  [Ch. X: DNN2](foo) of [Machine learning: a probabilistic perspective](http://people.cs.ubc.ca/~murphyk/MLbook/). This is work in progress, so expect rough edges.

| Tables   |      Are      |  Cool |
|----------|:-------------:|------:|
| col 1 is |  left-aligned | $1600 |
| col 2 is |    centered   |   $12 |
| col 3 is | right-aligned |    $1 |

# Recurrent neural networks (RNN)

In this section, we list some notebooks
that demonstrate how to use RNNs.

 (* denotes official TF tutorials, which are not part of the pyprobml repo.)

* [IMDB movie  review sentiment classification *](https://www.tensorflow.org/tutorials/text/text_classification_rnn)
* [Character level generation for Shakespeare *](https://www.tensorflow.org/tutorials/text/text_generation)
* [Time series forecasting *](https://www.tensorflow.org/tutorials/structured_data/time_series)
* [Image captioning *](https://www.tensorflow.org/tutorials/text/image_captioning)
* [Neural machine translation using RNN with attention *](https://www.tensorflow.org/tutorials/text/nmt_with_attention)
* [Deep neural networks I](https://github.com/probml/pyprobml/blob/master/notebooks/dnn/dnn.ipynb)

# Transformers

In this section, we give some examples of transformers using TF2.

 (* denotes official TF tutorials, which are not part of the pyprobml repo.)

 * [Portugese to English translation *](https://www.tensorflow.org/tutorials/text/transformer)

# Bayesian neural nets


*  [SVI for nonlinear regression in 1d](https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/dnn2/svi_nonlinear_regression_1d_tf.ipynb) 
