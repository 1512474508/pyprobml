{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "vae_image_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/lvm/vae_image_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xfNT-mlFwxVM"
      },
      "source": [
        "# Convolutional Variational Autoencoder for images\n",
        "\n",
        "Code is based on https://www.tensorflow.org/beta/tutorials/generative/cvae.\n",
        "We modified it in the following ways:\n",
        "- use FashionMNIST or CIFAR10 instead of MNIST\n",
        "- use tfds instead of keras.datasets\n",
        "- use larger learning rate\n",
        "\n",
        "For a version that uses TF probability library, see https://github.com/probml/pyprobml/blob/master/notebooks/lvm/vae_fashion_tfp.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import imageio\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## Load the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4fYMGxGhrna",
        "colab": {}
      },
      "source": [
        "#dataname = 'mnist' \n",
        "#dataname = 'fashion_mnist'\n",
        "dataname = 'cifar10'\n",
        "datasets, datasets_info = tfds.load(name=dataname, with_info=True, as_supervised=False)\n",
        "print(datasets_info)\n",
        "\n",
        "input_shape = datasets_info.features['image'].shape\n",
        "print(input_shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxmv3fddWa2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsize = 256\n",
        "# We extract the image from the dict, and drop the label\n",
        "# Then we scale it to [0,1] and optionally binarize\n",
        "\n",
        "if dataname == 'mnist':\n",
        "    def _preprocess(sample):\n",
        "      img = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
        "      #image = img < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
        "      # Statically binarize\n",
        "      image = img\n",
        "      image[img >= 0.5] = 1.\n",
        "      image[img < 0.5] = 0.\n",
        "      return image\n",
        "else:\n",
        "  def _preprocess(sample):\n",
        "      image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
        "      return image # for validation we compute p(input|input)\n",
        "  \n",
        "\n",
        "train_dataset = (datasets['train']\n",
        "                 .map(_preprocess)\n",
        "                 .batch(batchsize)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "                 .shuffle(int(10e3)))\n",
        "test_dataset = (datasets['test']\n",
        "                .map(_preprocess)\n",
        "                .batch(batchsize)\n",
        "                .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV6me0faW6pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for batch in train_dataset:\n",
        "  print(batch.shape)\n",
        "  i += 1\n",
        "  if i > 2:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC9lKHWvXkRh",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VGLbvBEmjK0a",
        "colab": {}
      },
      "source": [
        "class ConvVAE(tf.keras.Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(ConvVAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.inference_net = tf.keras.Sequential(\n",
        "      [\n",
        "          tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          # No activation\n",
        "          tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "   ]\n",
        "    )\n",
        "\n",
        "    nrows = input_shape[0]\n",
        "    ncols = input_shape[1]\n",
        "    nrows_latent = int(nrows/4) # two layers on transposedconv with stride 2\n",
        "    ncols_latent = int(ncols/4)\n",
        "    num_colors = input_shape[2]\n",
        "    self.generative_net = tf.keras.Sequential(\n",
        "        [\n",
        "          tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "          tf.keras.layers.Dense(units=nrows_latent*ncols_latent*32, activation=tf.nn.relu),\n",
        "          tf.keras.layers.Reshape(target_shape=(nrows_latent, ncols_latent, 32)),\n",
        "          tf.keras.layers.Conv2DTranspose(\n",
        "              filters=64,\n",
        "              kernel_size=3,\n",
        "              strides=(2, 2),\n",
        "              padding=\"SAME\",\n",
        "              activation='relu'),\n",
        "          tf.keras.layers.Conv2DTranspose(\n",
        "              filters=32,\n",
        "              kernel_size=3,\n",
        "              strides=(2, 2),\n",
        "              padding=\"SAME\",\n",
        "              activation='relu'),\n",
        "          # No activation\n",
        "          tf.keras.layers.Conv2DTranspose(\n",
        "              filters=num_colors, kernel_size=3, strides=(1, 1), padding=\"SAME\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "  @tf.function\n",
        "  def sample(self, eps=None):\n",
        "    if eps is None:\n",
        "      nsamples  = 1\n",
        "      eps = tf.random.normal(shape=(nsamples, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.generative_net(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss function and the optimizer\n",
        "\n",
        "VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood:\n",
        "\n",
        "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
        "\n",
        "In practice, we optimize the single sample Monte Carlo estimate of this expectation:\n",
        "\n",
        "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
        "where $z$ is sampled from $q(z|x)$.\n",
        "\n",
        "**Note**: we could also analytically compute the KL term, but here we incorporate all three terms in the Monte Carlo estimator for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iWCn_PVdEJZ7",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis=raxis)\n",
        "\n",
        "@tf.function\n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(model, x, optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "# Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "source": [
        "latent_dim = 50\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# keeping the random vector constant for generation (prediction) so\n",
        "# it will be easier to see the improvement.\n",
        "random_vector_for_generation = tf.random.normal(\n",
        "    shape=[num_examples_to_generate, latent_dim])\n",
        "model = ConvVAE(latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "num_colors = input_shape[2]\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = model.sample(test_input)\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      if num_colors == 1:\n",
        "         plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "      else:\n",
        "         plt.imshow(predictions[i, :, :, :])\n",
        "      plt.axis('off')\n",
        "\n",
        "  # tight_layout minimizes the overlap between 2 sub-plots\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "generate_and_save_images(model, 0, random_vector_for_generation)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EK1dkrKuHTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input=random_vector_for_generation\n",
        "predictions = model.sample(test_input)\n",
        "print(test_input.shape)\n",
        "print(predictions.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXZbv52pyIhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch_start = 10 # 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "epochs=10\n",
        "\n",
        "for epoch in range(epoch_start+1, epoch_start + epochs):\n",
        "  start_time = time.time()\n",
        "  for train_x in train_dataset:\n",
        "    compute_apply_gradients(model, train_x, optimizer)\n",
        "  end_time = time.time()\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    loss = tf.keras.metrics.Mean()\n",
        "    for test_x in test_dataset:\n",
        "      loss(compute_loss(model, test_x))\n",
        "    elbo = -loss.result()\n",
        "    display.clear_output(wait=False)\n",
        "    print('Epoch: {}, Test set ELBO: {}, '\n",
        "          'time elapse for current epoch {}'.format(epoch,\n",
        "                                                    elbo,\n",
        "                                                    end_time - start_time))\n",
        "    generate_and_save_images(\n",
        "        model, epoch, random_vector_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "### Display stored images of intermediate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfO5wCdclHGL",
        "colab": {}
      },
      "source": [
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5x3q9_Oe5q0A",
        "colab": {}
      },
      "source": [
        "plt.imshow(display_image(epochs))\n",
        "plt.axis('off')# Display images"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}