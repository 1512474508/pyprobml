{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_intro.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/intro/tf_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX4GSX3Fwt1S"
      },
      "source": [
        "# Introduction to tensorflow 2.0\n",
        "\n",
        "We show some simple examples of how to use TF 2.0 via the keras interface. \n",
        "\n",
        "**Make sure you select 'GPU' from the 'Runtime' tab at the top of this page.**\n",
        "\n",
        "For more details, see \n",
        "\n",
        "* [The official TF tutorials](https://www.tensorflow.org/beta/tutorials)\n",
        "* [\"Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow v2\"](https://github.com/ageron/handson-ml2), an excellent book by Aurelion Geron.\n",
        "* [\"Deep learning with Python\"](https://github.com/fchollet/deep-learning-with-python-notebooks), a short book by Francois Chollet on Keras.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7H7qrB8xT8J"
      },
      "source": [
        "# Standard Python libraries\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import imageio\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import seaborn as sns;\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('precision', 2) # 2 decimal places\n",
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', 30)\n",
        "pd.set_option('display.width', 100) # wide windows\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKbnIRmcwswg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b7553a-2fc7-4547-aca3-a7587324145d"
      },
      "source": [
        "# Tensorflow 2.0\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"tf version {}\".format(tf.__version__))\n",
        "if tf.test.is_gpu_available():\n",
        "    print(tf.test.gpu_device_name())\n",
        "else:\n",
        "    print(\"TF cannot find GPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version 2.4.0\n",
            "WARNING:tensorflow:From <ipython-input-2-583b80e4d332>:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Ch6dNWw1Ir"
      },
      "source": [
        "# Make an MLP \n",
        "\n",
        "See examples at https://github.com/probml/pyprobml/tree/master/book1/mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkUsOZv3GZjg"
      },
      "source": [
        "# Tensorflow datasets (TFDS)\n",
        "\n",
        "Tensorflow has an easy way to load data, and convert it into a stream of miniatches, as we show below.\n",
        "\n",
        "\n",
        "The functionality similar functionality to PyTorch DataLoader, but natively supports infinite streams via the `repeat` function. Also, all minibatches have the same size (note how we 'wrap around' the dataset).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAieu0vO6Twb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197de859-e709-4673-b9c8-f00cce5748bf"
      },
      "source": [
        "N_train = 5\n",
        "D = 4            \n",
        "np.random.seed(0)\n",
        "X = np.random.randn(N_train, D)\n",
        "y = np.random.randn(N_train)\n",
        "print(y)\n",
        "batch_size = 2\n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"X\": X, \"y\": y})\n",
        "batches = dataset.repeat().batch(batch_size)\n",
        "\n",
        "print('batchified version')\n",
        "step = 0\n",
        "num_minibatches = 4\n",
        "for batch in batches:\n",
        "    if step >= num_minibatches:\n",
        "        break\n",
        "    # print(type(batch[\"X\"])) #<class 'tensorflow.python.framework.ops.EagerTensor'\n",
        "    x, y = batch[\"X\"].numpy(), batch[\"y\"].numpy()\n",
        "    print(y)\n",
        "    step = step + 1\n",
        "\n",
        "\n",
        "print('batchified version v2')\n",
        "batch_stream = batches.as_numpy_iterator()\n",
        "for step in range(num_minibatches):\n",
        "  batch = batch_stream.next()\n",
        "  # print(type(batch[\"X\"])) #<class 'numpy.ndarray'>\n",
        "  x, y = batch[\"X\"], batch[\"y\"]\n",
        "  print(y)\n",
        "  step = step + 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.55298982  0.6536186   0.8644362  -0.74216502  2.26975462]\n",
            "batchified version\n",
            "[-2.55298982  0.6536186 ]\n",
            "[ 0.8644362  -0.74216502]\n",
            "[ 2.26975462 -2.55298982]\n",
            "[0.6536186 0.8644362]\n",
            "batchified version v2\n",
            "[-2.55298982  0.6536186 ]\n",
            "[ 0.8644362  -0.74216502]\n",
            "[ 2.26975462 -2.55298982]\n",
            "[0.6536186 0.8644362]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1x8_e0zHUkh"
      },
      "source": [
        "\n",
        "TF also has preprocessed datasets, available from\n",
        "https://www.tensorflow.org/datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMtH7PVMHMw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0385e3-fb4d-4045-9e70-a1d207a581f5"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
        "\n",
        "batches = dataset.repeat().batch(batch_size)\n",
        "\n",
        "step = 0\n",
        "for batch in batches:\n",
        "    if step >= num_minibatches:\n",
        "        break\n",
        "    X, y = batch['image'], batch['label']\n",
        "    print(type(X))\n",
        "    print(X.shape)\n",
        "    step = step + 1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "(2, 28, 28, 1)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "(2, 28, 28, 1)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "(2, 28, 28, 1)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "(2, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeA-74IU124h"
      },
      "source": [
        "# Autodiff\n",
        "\n",
        "We use binary logistic regression as an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az0915TG19Sl",
        "outputId": "520c6034-6f11-4bc9-cd5a-3f3a024e8c25"
      },
      "source": [
        "## Compute gradient of loss \"by hand\" using numpy\n",
        "\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "def BCE_with_logits(logits, targets):\n",
        "    N = logits.shape[0]\n",
        "    logits = logits.reshape(N,1)\n",
        "    logits_plus = np.hstack([np.zeros((N,1)), logits]) # e^0=1\n",
        "    logits_minus = np.hstack([np.zeros((N,1)), -logits])\n",
        "    logp1 = -logsumexp(logits_minus, axis=1)\n",
        "    logp0 = -logsumexp(logits_plus, axis=1)\n",
        "    logprobs = logp1 * targets + logp0 * (1-targets)\n",
        "    return -np.sum(logprobs)/N\n",
        "\n",
        "def sigmoid(x): return 0.5 * (np.tanh(x / 2.) + 1)\n",
        "\n",
        "def predict_logit(weights, inputs):\n",
        "    return np.dot(inputs, weights) # Already vectorized\n",
        "\n",
        "def predict_prob(weights, inputs):\n",
        "    return sigmoid(predict_logit(weights, inputs))\n",
        "\n",
        "def NLL(weights, batch):\n",
        "    X, y = batch\n",
        "    logits = predict_logit(weights, X)\n",
        "    return BCE_with_logits(logits, y)\n",
        "\n",
        "def NLL_grad(weights, batch):\n",
        "    X, y = batch\n",
        "    N = X.shape[0]\n",
        "    mu = predict_prob(weights, X)\n",
        "    g = np.sum(np.dot(np.diag(mu - y), X), axis=0)/N\n",
        "    return g\n",
        "\n",
        "np.random.seed(0)\n",
        "N = 100\n",
        "D = 5\n",
        "X = np.random.randn(N, D)\n",
        "w = 10*np.random.randn(D)\n",
        "mu = predict_prob(w, X)\n",
        "y = np.random.binomial(n=1, p=mu, size=N)\n",
        "\n",
        "X_test = X\n",
        "y_test = y\n",
        "\n",
        "y_pred = predict_prob(w, X_test)\n",
        "loss = NLL(w, (X_test, y_test))\n",
        "grad_np = NLL_grad(w, (X_test, y_test))\n",
        "print(\"params {}\".format(w))\n",
        "#print(\"pred {}\".format(y_pred))\n",
        "print(\"loss {}\".format(loss))\n",
        "print(\"grad {}\".format(grad_np))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params [ 3.8273243  -0.34242281 10.96346846 -2.34215801 -3.47450652]\n",
            "loss 0.05501843790657687\n",
            "grad [-0.01360904  0.00325892  0.00844617  0.00848175  0.01390088]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekyo0EEO2KL7",
        "outputId": "1ac5fdb2-1307-4650-ed36-a9a8744f2878"
      },
      "source": [
        "\n",
        "w_tf = tf.Variable(np.reshape(w, (D,1)))  \n",
        "x_test_tf = tf.convert_to_tensor(X_test, dtype=np.float64) \n",
        "y_test_tf = tf.convert_to_tensor(np.reshape(y_test, (-1,1)), dtype=np.float64)\n",
        "with tf.GradientTape() as tape:\n",
        "    logits = tf.linalg.matmul(x_test_tf, w_tf)\n",
        "    y_pred = tf.math.sigmoid(logits)\n",
        "    loss_batch = tf.nn.sigmoid_cross_entropy_with_logits(y_test_tf, logits)\n",
        "    loss_tf = tf.reduce_mean(loss_batch, axis=0)\n",
        "grad_tf = tape.gradient(loss_tf, [w_tf])\n",
        "grad_tf = grad_tf[0][:,0].numpy()\n",
        "assert np.allclose(grad_np, grad_tf)\n",
        "\n",
        "print(\"params {}\".format(w_tf))\n",
        "#print(\"pred {}\".format(y_pred))\n",
        "print(\"loss {}\".format(loss_tf))\n",
        "print(\"grad {}\".format(grad_tf))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params <tf.Variable 'Variable:0' shape=(5, 1) dtype=float64, numpy=\n",
            "array([[ 3.8273243 ],\n",
            "       [-0.34242281],\n",
            "       [10.96346846],\n",
            "       [-2.34215801],\n",
            "       [-3.47450652]])>\n",
            "loss [0.05501844]\n",
            "grad [-0.01360904  0.00325892  0.00844617  0.00848175  0.01390088]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}